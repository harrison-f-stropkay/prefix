# Single-node, 8Ã—GPU training defaults.
distributed:
  world_size: 8
  backend: nccl
checkpointing:
  enabled: true
  save_every_steps: 1000
  keep_last: 3
per_gpu_batch_size: 16
